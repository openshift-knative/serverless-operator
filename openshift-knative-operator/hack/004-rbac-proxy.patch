diff --git a/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/2-serving-core.yaml b/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/2-serving-core.yaml
index 8e15a4d8..81dbd549 100644
--- a/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/2-serving-core.yaml
+++ b/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/2-serving-core.yaml
@@ -2216,6 +2216,8 @@ spec:
             # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
             - name: METRICS_DOMAIN
               value: knative.dev/internal/serving
+            - name: METRICS_PROMETHEUS_HOST
+              value: "127.0.0.1"
           securityContext:
             allowPrivilegeEscalation: false
             readOnlyRootFilesystem: true
@@ -2247,6 +2249,26 @@ spec:
                   value: "activator"
             failureThreshold: 12
             initialDelaySeconds: 15
+        - name: kube-rbac-proxy
+          image: registry.ci.openshift.org/origin/4.7:kube-rbac-proxy
+          volumeMounts:
+            - mountPath: /etc/tls/private
+              name: secret-activator-sm-service-tls
+          resources:
+            requests:
+              memory: 20Mi
+              cpu: 10m
+          args:
+            - "--secure-listen-address=0.0.0.0:8444"
+            - "--upstream=http://127.0.0.1:9090/"
+            - "--tls-cert-file=/etc/tls/private/tls.crt"
+            - "--tls-private-key-file=/etc/tls/private/tls.key"
+            - "--logtostderr=true"
+            - "--v=10"
+      volumes:
+        - name: secret-activator-sm-service-tls
+          secret:
+            secretName: activator-sm-service-tls
       # The activator (often) sits on the dataplane, and may proxy long (e.g.
       # streaming, websockets) requests.  We give a long grace period for the
       # activator to "lame duck" and drain outstanding requests before we
@@ -2361,6 +2383,8 @@ spec:
             # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
             - name: METRICS_DOMAIN
               value: knative.dev/serving
+            - name: METRICS_PROMETHEUS_HOST
+              value: "127.0.0.1"
           securityContext:
             allowPrivilegeEscalation: false
             readOnlyRootFilesystem: true
@@ -2388,6 +2412,26 @@ spec:
                 - name: k-kubelet-probe
                   value: "autoscaler"
             failureThreshold: 6
+        - name: kube-rbac-proxy
+          image: registry.ci.openshift.org/origin/4.7:kube-rbac-proxy
+          volumeMounts:
+            - mountPath: /etc/tls/private
+              name: secret-autoscaler-sm-service-tls
+          resources:
+            requests:
+              memory: 20Mi
+              cpu: 10m
+          args:
+            - "--secure-listen-address=0.0.0.0:8444"
+            - "--upstream=http://127.0.0.1:9090/"
+            - "--tls-cert-file=/etc/tls/private/tls.crt"
+            - "--tls-private-key-file=/etc/tls/private/tls.key"
+            - "--logtostderr=true"
+            - "--v=10"
+      volumes:
+        - name: secret-autoscaler-sm-service-tls
+          secret:
+            secretName: autoscaler-sm-service-tls
 ---
 apiVersion: v1
 kind: Service
@@ -2485,6 +2529,8 @@ spec:
             # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
             - name: METRICS_DOMAIN
               value: knative.dev/internal/serving
+            - name: METRICS_PROMETHEUS_HOST
+              value: "127.0.0.1"
           securityContext:
             allowPrivilegeEscalation: false
             readOnlyRootFilesystem: true
@@ -2497,6 +2543,26 @@ spec:
               containerPort: 9090
             - name: profiling
               containerPort: 8008
+        - name: kube-rbac-proxy
+          image: registry.ci.openshift.org/origin/4.7:kube-rbac-proxy
+          volumeMounts:
+            - mountPath: /etc/tls/private
+              name: secret-controller-sm-service-tls
+          resources:
+            requests:
+              memory: 20Mi
+              cpu: 10m
+          args:
+            - "--secure-listen-address=0.0.0.0:8444"
+            - "--upstream=http://127.0.0.1:9090/"
+            - "--tls-cert-file=/etc/tls/private/tls.crt"
+            - "--tls-private-key-file=/etc/tls/private/tls.key"
+            - "--logtostderr=true"
+            - "--v=10"
+      volumes:
+        - name: secret-controller-sm-service-tls
+          secret:
+            secretName: controller-sm-service-tls
 ---
 apiVersion: v1
 kind: Service
@@ -2647,6 +2713,8 @@ spec:
             # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
             - name: METRICS_DOMAIN
               value: knative.dev/internal/serving
+            - name: METRICS_PROMETHEUS_HOST
+              value: "127.0.0.1"
           securityContext:
             allowPrivilegeEscalation: false
             readOnlyRootFilesystem: true
@@ -2673,6 +2741,26 @@ spec:
             !!merge <<: *probe
             failureThreshold: 6
             initialDelaySeconds: 20
+        - name: kube-rbac-proxy
+          image: registry.ci.openshift.org/origin/4.7:kube-rbac-proxy
+          volumeMounts:
+            - mountPath: /etc/tls/private
+              name: secret-webhook-sm-service-tls
+          resources:
+            requests:
+              memory: 20Mi
+              cpu: 10m
+          args:
+            - "--secure-listen-address=0.0.0.0:8444"
+            - "--upstream=http://127.0.0.1:9090/"
+            - "--tls-cert-file=/etc/tls/private/tls.crt"
+            - "--tls-private-key-file=/etc/tls/private/tls.key"
+            - "--logtostderr=true"
+            - "--v=10"
+      volumes:
+        - name: secret-webhook-sm-service-tls
+          secret:
+            secretName: webhook-sm-service-tls
       # Our webhook should gracefully terminate by lame ducking first, set this to a sufficiently
       # high value that we respect whatever value it has configured for the lame duck grace period.
       terminationGracePeriodSeconds: 300
diff --git a/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/3-serving-hpa.yaml b/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/3-serving-hpa.yaml
index 5c2ae1d5..4cc33302 100644
--- a/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/3-serving-hpa.yaml
+++ b/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/3-serving-hpa.yaml
@@ -67,6 +67,8 @@ spec:
             # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
             - name: METRICS_DOMAIN
               value: knative.dev/serving
+            - name: METRICS_PROMETHEUS_HOST
+              value: "127.0.0.1"
           securityContext:
             allowPrivilegeEscalation: false
             readOnlyRootFilesystem: true
@@ -79,6 +81,26 @@ spec:
               containerPort: 9090
             - name: profiling
               containerPort: 8008
+        - name: kube-rbac-proxy
+          image: registry.ci.openshift.org/origin/4.7:kube-rbac-proxy
+          volumeMounts:
+            - mountPath: /etc/tls/private
+              name: secret-autoscaler-hpa-sm-service-tls
+          resources:
+            requests:
+              memory: 20Mi
+              cpu: 10m
+          args:
+            - "--secure-listen-address=0.0.0.0:8444"
+            - "--upstream=http://127.0.0.1:9090/"
+            - "--tls-cert-file=/etc/tls/private/tls.crt"
+            - "--tls-private-key-file=/etc/tls/private/tls.key"
+            - "--logtostderr=true"
+            - "--v=10"
+      volumes:
+        - name: secret-autoscaler-hpa-sm-service-tls
+          secret:
+            secretName: autoscaler-hpa-sm-service-tls
 ---
 apiVersion: v1
 kind: Service
diff --git a/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/5-serving-domainmapping.yaml b/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/5-serving-domainmapping.yaml
index a980952f..bcee5d5d 100644
--- a/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/5-serving-domainmapping.yaml
+++ b/openshift-knative-operator/cmd/operator/kodata/knative-serving/0.20.0/5-serving-domainmapping.yaml
@@ -175,6 +175,8 @@ spec:
             # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
             - name: METRICS_DOMAIN
               value: knative.dev/serving
+            - name: METRICS_PROMETHEUS_HOST
+              value: "127.0.0.1"
           securityContext:
             allowPrivilegeEscalation: false
             readOnlyRootFilesystem: true
@@ -187,6 +189,26 @@ spec:
               containerPort: 9090
             - name: profiling
               containerPort: 8008
+        - name: kube-rbac-proxy
+          image: registry.ci.openshift.org/origin/4.7:kube-rbac-proxy
+          volumeMounts:
+            - mountPath: /etc/tls/private
+              name: secret-domain-mapping-sm-service-tls
+          resources:
+            requests:
+              memory: 20Mi
+              cpu: 10m
+          args:
+            - "--secure-listen-address=0.0.0.0:8444"
+            - "--upstream=http://127.0.0.1:9090/"
+            - "--tls-cert-file=/etc/tls/private/tls.crt"
+            - "--tls-private-key-file=/etc/tls/private/tls.key"
+            - "--logtostderr=true"
+            - "--v=10"
+      volumes:
+        - name: secret-domain-mapping-sm-service-tls
+          secret:
+            secretName: domain-mapping-sm-service-tls

 ---
 # Copyright 2020 The Knative Authors
@@ -265,6 +287,8 @@ spec:
             # TODO(https://github.com/knative/pkg/pull/953): Remove stackdriver specific config
             - name: METRICS_DOMAIN
               value: knative.dev/serving
+            - name: METRICS_PROMETHEUS_HOST
+              value: "127.0.0.1"
           securityContext:
             allowPrivilegeEscalation: false
           ports:
@@ -286,6 +310,26 @@ spec:
             !!merge <<: *probe
             failureThreshold: 6
             initialDelaySeconds: 20
+        - name: kube-rbac-proxy
+          image: registry.ci.openshift.org/origin/4.7:kube-rbac-proxy
+          volumeMounts:
+            - mountPath: /etc/tls/private
+              name: secret-domainmapping-webhook-sm-service-tls
+          resources:
+            requests:
+              memory: 20Mi
+              cpu: 10m
+          args:
+            - "--secure-listen-address=0.0.0.0:8444"
+            - "--upstream=http://127.0.0.1:9090/"
+            - "--tls-cert-file=/etc/tls/private/tls.crt"
+            - "--tls-private-key-file=/etc/tls/private/tls.key"
+            - "--logtostderr=true"
+            - "--v=10"
+      volumes:
+        - name: secret-domainmapping-webhook-sm-service-tls
+          secret:
+            secretName: domainmapping-webhook-sm-service-tls
       # Our webhook should gracefully terminate by lame ducking first, set this to a sufficiently
       # high value that we respect whatever value it has configured for the lame duck grace period.
       terminationGracePeriodSeconds: 300
